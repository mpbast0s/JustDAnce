{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oi\n"
     ]
    }
   ],
   "source": [
    "print('oi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\usuario\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\usuario\\anaconda3\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\usuario\\anaconda3\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\usuario\\anaconda3\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='lite-model_movenet_singlepose_lightning_3.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}\n",
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Reshape image\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\n",
    "    input_image = tf.cast(img, dtype=tf.float32)\n",
    "    \n",
    "    # Setup input and output \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Make predictions \n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    interpreter.invoke()\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    # Rendering \n",
    "    draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "    draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "    \n",
    "    cv2.imshow('MoveNet Lightning', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.2587693  0.8690356  0.03037726]\n",
      "   [0.25334713 0.86989635 0.02533793]\n",
      "   [0.78168267 0.10936028 0.04068818]\n",
      "   [0.44688687 0.9505388  0.02517667]\n",
      "   [0.55848366 0.7325711  0.01641007]\n",
      "   [0.2216038  0.8492098  0.04313627]\n",
      "   [0.79179573 0.72134084 0.07201925]\n",
      "   [0.4504878  0.80029213 0.00874515]\n",
      "   [0.43406078 0.2943107  0.02511298]\n",
      "   [0.5785262  0.7309634  0.01924617]\n",
      "   [0.5994599  0.39079246 0.00995755]\n",
      "   [0.6023626  0.6537951  0.03190909]\n",
      "   [0.61006    0.3718326  0.01893109]\n",
      "   [0.78490126 0.5931847  0.05001868]\n",
      "   [0.7925016  0.37894088 0.02948918]\n",
      "   [0.8185224  0.5459735  0.02048366]\n",
      "   [0.82499355 0.43179715 0.03275386]]]]\n"
     ]
    }
   ],
   "source": [
    "print(keypoints_with_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(0) # Abre a câmera padrão do computador\n",
    "fps = 30 # FPS desejado\n",
    "\n",
    "while True:\n",
    "    # Marca o tempo inicial\n",
    "    start_time = cv2.getTickCount() \n",
    "    start_tm = time.time() \n",
    "\n",
    "    # Código para capturar e processar o frame aqui\n",
    "    ret, frame = cap.read()\n",
    "     \n",
    "    # Calcula o tempo de espera necessário para atingir o FPS desejado\n",
    "    time_per_frame = cv2.getTickCount() - start_time\n",
    "    time_per_frame /= cv2.getTickFrequency()\n",
    "    wait_time = max(1, int((1000/fps) - time_per_frame))\n",
    "    \n",
    "    #ainda não está como eu queriaaaaa\n",
    "    #####\n",
    "    fpss = int(1.0 / (time.time() - start_tm))\n",
    "    fps_text = \"FPS: \" + str(fpss)\n",
    "    \n",
    "    cv2.putText(frame,fps_text,(10,30),cv2.FONT_HERSHEY_PLAIN,1,255)\n",
    "    \n",
    "    cv2.imshow('JustDance 2.1', frame)\n",
    "\n",
    "    if cv2.waitKey(wait_time) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(0) # Abre a câmera padrão do computador\n",
    "fps = 30 # FPS desejado\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "     # Marca o tempo inicial\n",
    "    start_time = cv2.getTickCount() \n",
    "    start_tm = time.time() \n",
    "    \n",
    "    # Reshape image\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\n",
    "    input_image = tf.cast(img, dtype=tf.float32)\n",
    "    \n",
    "    # Setup input and output \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Make predictions \n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    interpreter.invoke()\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    # Rendering \n",
    "   # draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "    draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "    \n",
    "    \n",
    "    # Calcula o tempo de espera necessário para atingir o FPS desejado\n",
    "    time_per_frame = cv2.getTickCount() - start_time\n",
    "    time_per_frame /= cv2.getTickFrequency()\n",
    "    wait_time = max(1, int((1000/fps) - time_per_frame))\n",
    "    \n",
    "    #ainda não está como eu queriaaaaa\n",
    "    #####\n",
    "    fpss = int(1.0 / (time.time() - start_tm))\n",
    "    fps_text = \"FPS: \" + str(fpss)\n",
    "    \n",
    "    cv2.putText(frame,fps_text,(10,30),cv2.FONT_HERSHEY_PLAIN,1,255)\n",
    "    \n",
    "    cv2.imshow('JustDance 2.1', frame)\n",
    "\n",
    "    if cv2.waitKey(wait_time) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(\"meuvideo.mp4\") # Abre a câmera padrão do computador\n",
    "fps = 30 # FPS desejado\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "     # Marca o tempo inicial\n",
    "    start_time = cv2.getTickCount() \n",
    "    start_tm = time.time() \n",
    "    \n",
    "    # Reshape image\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\n",
    "    input_image = tf.cast(img, dtype=tf.float32)\n",
    "    \n",
    "    # Setup input and output \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Make predictions \n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "    interpreter.invoke()\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    # Rendering \n",
    "   # draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "    draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "    \n",
    "    \n",
    "    # Calcula o tempo de espera necessário para atingir o FPS desejado\n",
    "    time_per_frame = cv2.getTickCount() - start_time\n",
    "    time_per_frame /= cv2.getTickFrequency()\n",
    "    wait_time = max(1, int((1000/fps) - time_per_frame))\n",
    "    \n",
    "    #ainda não está como eu queriaaaaa\n",
    "    #####\n",
    "    fpss = int(1.0 / (time.time() - start_tm))\n",
    "    fps_text = \"FPS: \" + str(fpss)\n",
    "    \n",
    "    cv2.putText(frame,fps_text,(10,30),cv2.FONT_HERSHEY_PLAIN,1,255)\n",
    "    \n",
    "    cv2.imshow('JustDance 2.1', frame)\n",
    "\n",
    "    if cv2.waitKey(wait_time) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in c:\\users\\usuario\\anaconda3\\lib\\site-packages (12.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome do arquivo: meuvideo\n",
      "Digite o link do vídeo do YouTube: https://www.youtube.com/watch?v=jPa748Wvo6M&ab_channel=CaaSilva\n"
     ]
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "def baixar_video(link, titulovideo):\n",
    "    # URL do vídeo do YouTube\n",
    "    # url = \"https://www.youtube.com/watch?v=jPa748Wvo6M&ab_channel=CaaSilva\"\n",
    "\n",
    "    # Nome desejado para o arquivo de saída\n",
    "    output_filename = titulovideo\n",
    "\n",
    "    # Criar um objeto da classe YouTube\n",
    "    yt = YouTube(link)\n",
    "\n",
    "    # Selecionar a melhor qualidade disponível\n",
    "    ys = yt.streams.filter(progressive=True, res=\"360p\").first()\n",
    "    #stream = video.streams.filter(progressive=True, res=\"360p\").first()\n",
    "\n",
    "\n",
    "    # Fazer o download do vídeo com o nome desejado\n",
    "    #ys.download(output_path='./', filename=output_filename)\n",
    "    ys.download(filename=output_filename)\n",
    "    return\n",
    "\n",
    "titulo = input(\"Nome do arquivo: \")\n",
    "titulovideo = titulo + \".mp4\"\n",
    "link = input(\"Digite o link do vídeo do YouTube: \")\n",
    "baixar_video(link, titulovideo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import csv\n",
    "filename = titulo + \".csv\"\n",
    "output_images = []\n",
    "numero_frames = 0\n",
    "\n",
    "cap = cv2.VideoCapture(titulovideo) # Abre a câmera padrão do computador\n",
    "#fps = 30 # FPS desejado\n",
    "\n",
    "with open(filename, 'w') as csvfile:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        # Check if frame was read successfully\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "         # Marca o tempo inicial\n",
    "        start_time = cv2.getTickCount() \n",
    "        start_tm = time.time() \n",
    "\n",
    "        # Reshape image\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\n",
    "        input_image = tf.cast(img, dtype=tf.float32)\n",
    "        \n",
    "\n",
    "        # Setup input and output \n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "\n",
    "        # Make predictions \n",
    "        interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "        interpreter.invoke()\n",
    "        keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "        # Rendering \n",
    "        draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "        draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "\n",
    "        #pegar keypoints:\n",
    "        keypoints_with_scores_new = []\n",
    "        for sample in keypoints_with_scores:\n",
    "          new_sample = []\n",
    "          for person in sample:\n",
    "              new_person = []\n",
    "              for index, keypoint in enumerate(person):\n",
    "                  # Adicionar o índice antes de cada trio\n",
    "                  new_person.append([index] + keypoint.tolist())\n",
    "              new_sample.append(new_person)\n",
    "          keypoints_with_scores_new.append(new_sample)\n",
    "\n",
    "          indices_desejados = [0] + list(range(5, 17))\n",
    "          csvwriter = csv.writer(csvfile)\n",
    "          for row in keypoints_with_scores_new:\n",
    "            for row in row:\n",
    "              for row in row:\n",
    "                  if row[0] in indices_desejados:\n",
    "                    csvwriter.writerow(row)\n",
    "\n",
    "\n",
    "        #ainda não está como eu queriaaaaa\n",
    "        #####\n",
    "        #fpss = int(1.0 / (time.time() - start_tm))\n",
    "        #fps_text = \"FPS: \" + str(fpss)\n",
    "\n",
    "        #cv2.putText(frame,fps_text,(10,30),cv2.FONT_HERSHEY_PLAIN,1,255)\n",
    "        \n",
    "        numero_frames = numero_frames + 1\n",
    "        \n",
    "        cv2.imshow('JustDance 2.3', frame)\n",
    "\n",
    "        if cv2.waitKey(wait_time) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\users\\usuario\\anaconda3\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from moviepy) (1.21.5)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from moviepy) (2.28.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from moviepy) (2.19.3)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from moviepy) (0.4.8)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from moviepy) (4.64.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (9.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titulovideo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9720\\2430623775.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Carregar o arquivo de vídeo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mvideo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitulovideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Obter a duração do vídeo em segundos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'titulovideo' is not defined"
     ]
    }
   ],
   "source": [
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "\n",
    "# Carregar o arquivo de vídeo\n",
    "video = VideoFileClip(titulovideo)\n",
    "\n",
    "# Obter a duração do vídeo em segundos\n",
    "duracao = video.duration\n",
    "\n",
    "# Imprimir a duração do vídeo em segundos\n",
    "print(\"Duração do vídeo:\", duracao, \"segundos\")\n",
    "\n",
    "# Fechar o arquivo de vídeo\n",
    "video.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numero_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0575296108291032\n"
     ]
    }
   ],
   "source": [
    "fps = numero_frames / duracao\n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def angle_between_points(a, b, c):\n",
    "    \"\"\"\n",
    "    Calculates the angle between three points (a, b, c) represented as (x, y) coordinates.\n",
    "    The angle is calculated at point b.\n",
    "    a = [x, y, score]\n",
    "    b = []\n",
    "    \"\"\"\n",
    "    # Calculate the vectors ab and bc\n",
    "    ab = (a[0] - b[0], a[1] - b[1])\n",
    "    bc = (c[0] - b[0], c[1] - b[1])\n",
    "    \n",
    "    # Calculate the dot product and the magnitude of each vector\n",
    "    dot_product = ab[0]*bc[0] + ab[1]*bc[1]\n",
    "    magnitude_ab = math.sqrt(ab[0]**2 + ab[1]**2)\n",
    "    magnitude_bc = math.sqrt(bc[0]**2 + bc[1]**2)\n",
    "    \n",
    "    # Calculate the cosine of the angle using the dot product and magnitudes\n",
    "    cos_angle = dot_product / (magnitude_ab * magnitude_bc)\n",
    "    \n",
    "    # Calculate the angle in radians and convert it to degrees\n",
    "    angle_in_radians = math.acos(cos_angle)\n",
    "    angle_in_degrees = math.degrees(angle_in_radians)\n",
    "    \n",
    "    #calculo da media dos scores:\n",
    "    media_1 =( a[2] +  b[2] + c[2])/3 \n",
    "    \n",
    "    return [ angle_in_degrees , media_1 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import csv\n",
    "titulo = \"meuvideo\"\n",
    "titulovideo = titulo + \".mp4\"\n",
    "filename = titulo + \"angulos.csv\"\n",
    "output_images = []\n",
    "numero_frames = 0\n",
    "\n",
    "cap = cv2.VideoCapture(titulovideo) # Abre a câmera padrão do computador\n",
    "#fps = 30 # FPS desejado\n",
    "\n",
    "with open(filename, 'w') as csvfile:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        # Check if frame was read successfully\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "         # Marca o tempo inicial\n",
    "        start_time = cv2.getTickCount() \n",
    "        start_tm = time.time() \n",
    "\n",
    "        # Reshape image\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\n",
    "        input_image = tf.cast(img, dtype=tf.float32)\n",
    "        \n",
    "\n",
    "        # Setup input and output \n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "\n",
    "        # Make predictions \n",
    "        interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "        interpreter.invoke()\n",
    "        keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "        # Rendering \n",
    "        draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "        draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "\n",
    "        #pegar keypoints:\n",
    "        keypoints_with_scores_new = []\n",
    "        for sample in keypoints_with_scores:\n",
    "          new_sample = []\n",
    "          for person in sample:\n",
    "              new_person = []\n",
    "              for index, keypoint in enumerate(person):\n",
    "                  # Adicionar o índice antes de cada trio\n",
    "                  new_person.append([index] + keypoint.tolist())\n",
    "              new_sample.append(new_person)\n",
    "          keypoints_with_scores_new.append(new_sample)\n",
    "\n",
    "          indices_desejados = [0] + list(range(5, 17))\n",
    "          csvwriter = csv.writer(csvfile)\n",
    "          keypoints_dict = {}\n",
    "          for row in keypoints_with_scores_new:\n",
    "            for row in row:\n",
    "              for row in row:\n",
    "                  if row[0] in indices_desejados:\n",
    "                   keypoints_dict[row[0]] = [row[1], row[2], row[3]]\n",
    "\n",
    "          key_0 = keypoints_dict.get(0)\n",
    "          key_5 = keypoints_dict.get(5)\n",
    "          key_6 = keypoints_dict.get(6)\n",
    "          key_7 = keypoints_dict.get(7)\n",
    "          key_8 = keypoints_dict.get(8)\n",
    "          key_9 = keypoints_dict.get(9)\n",
    "          key_10 = keypoints_dict.get(10)\n",
    "          key_11 = keypoints_dict.get(11)\n",
    "          key_12 = keypoints_dict.get(12)\n",
    "          key_13 = keypoints_dict.get(13)\n",
    "          key_14 = keypoints_dict.get(14)\n",
    "          key_15 = keypoints_dict.get(15)\n",
    "          key_16 = keypoints_dict.get(16)\n",
    "        \n",
    "                     \n",
    "        # Lista com as tuplas dos pontos para calcular os ângulos\n",
    "        pontos = [(key_5, key_0, key_6), \n",
    "                  (key_5, key_7, key_9), (key_6, key_8, key_10),\n",
    "                  (key_9, key_11, key_13), (key_10, key_12, key_14),\n",
    "                  (key_11, key_13, key_15), (key_12, key_14, key_16),]\n",
    "        \n",
    "        # Lista para armazenar os valores de ângulo\n",
    "        angulos = []\n",
    "\n",
    "        # Calcular e armazenar os ângulos\n",
    "        for p in pontos:\n",
    "            angulo = angle_between_points(*p)\n",
    "            angulos.append([angulo])\n",
    "\n",
    "        # Escrever os valores de ângulo no arquivo\n",
    "        for row in angulos:\n",
    "            for row in row:\n",
    "                csvwriter.writerow(row)\n",
    "\n",
    "\n",
    "\n",
    "        #ainda não está como eu queriaaaaa\n",
    "        #####\n",
    "        #fpss = int(1.0 / (time.time() - start_tm))\n",
    "        #fps_text = \"FPS: \" + str(fpss)\n",
    "\n",
    "        #cv2.putText(frame,fps_text,(10,30),cv2.FONT_HERSHEY_PLAIN,1,255)\n",
    "        \n",
    "        numero_frames = numero_frames + 1\n",
    "        \n",
    "        cv2.imshow('JustDance 2.4', frame)\n",
    "\n",
    "        if cv2.waitKey(wait_time) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3744058609008789, 0.5445709824562073, 0.1791815608739853]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0.3744058609008789, 0.5445709824562073, 0.1791815608739853],\n",
       " 5: [0.37277692556381226, 0.5184810161590576, 0.32008033990859985],\n",
       " 6: [0.3759048581123352, 0.5395008325576782, 0.4074215292930603],\n",
       " 7: [0.45141538977622986, 0.5247824192047119, 0.18586932122707367],\n",
       " 8: [0.461556077003479, 0.5702158212661743, 0.21028445661067963],\n",
       " 9: [0.4814530313014984, 0.556816041469574, 0.24485765397548676],\n",
       " 10: [0.48814281821250916, 0.5697234272956848, 0.25239214301109314],\n",
       " 11: [0.5046296119689941, 0.5201765298843384, 0.3116952180862427],\n",
       " 12: [0.5030608773231506, 0.53365159034729, 0.31794288754463196],\n",
       " 13: [0.6132531762123108, 0.5209109783172607, 0.3412189185619354],\n",
       " 14: [0.6077196598052979, 0.5346493721008301, 0.32865452766418457],\n",
       " 15: [0.7120239734649658, 0.5204124450683594, 0.4423971474170685],\n",
       " 16: [0.7123450040817261, 0.5178609490394592, 0.4256291091442108]}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35.73474361538644, 0.5280277331670126]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'angulos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_456\\2114438320.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mangulos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'angulos' is not defined"
     ]
    }
   ],
   "source": [
    "angulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Inicia captura de vídeo\n",
    "cap = cv2.VideoCapture('meuvideo.mp4')\n",
    "\n",
    "# Inicia captura de imagem da câmera\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Lê frame do vídeo\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Lê frame da câmera\n",
    "    ret_cam, frame_cam = cam.read()\n",
    "\n",
    "    frame = cv2.resize(frame, (int(frame.shape[1]/2), int(frame.shape[0]/2)))\n",
    "\n",
    "    # Corta a imagem da câmera para o mesmo tamanho do vídeo\n",
    "    # Corta a imagem da câmera centralmente\n",
    "    frame_cam = frame_cam[frame.shape[1]:frame_cam.shape[1],frame.shape[0]:frame_cam.shape[0]]\n",
    "    \n",
    "    # Redimensiona a imagem da câmera para que tenha o mesmo tamanho do vídeo\n",
    "    frame_cam = cv2.resize(frame_cam, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "    # Concatena as imagens horizontalmente\n",
    "    combined_frame = cv2.hconcat([frame, frame_cam])\n",
    "\n",
    "    # Exibe a imagem combinada em uma janela\n",
    "    cv2.imshow('Combined Video and Camera Feed', combined_frame)\n",
    "\n",
    "    # Aguarda 1ms por uma tecla para ser pressionada\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    # Verifica se o vídeo terminou\n",
    "    if not cap.isOpened():\n",
    "        break\n",
    "\n",
    "# Libera os recursos\n",
    "cap.release()\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_9720\\2652569074.py\", line 19, in iniciar_video\n",
      "    frame = cv2.resize(frame, (int(frame.shape[1]/2), int(frame.shape[0]/2)))\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "\n",
    "# Função a ser chamada quando o botão \"Começar\" for pressionado\n",
    "def iniciar_video():\n",
    "    # Inicia captura de vídeo\n",
    "    cap = cv2.VideoCapture('meuvideo.mp4')\n",
    "\n",
    "    # Inicia captura de imagem da câmera\n",
    "    cam = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Lê frame do vídeo\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Lê frame da câmera\n",
    "        ret_cam, frame_cam = cam.read()\n",
    "\n",
    "        frame = cv2.resize(frame, (int(frame.shape[1]/2), int(frame.shape[0]/2)))\n",
    "\n",
    "        # Corta a imagem da câmera para o mesmo tamanho do vídeo\n",
    "        # Corta a imagem da câmera centralmente\n",
    "        frame_cam = frame_cam[frame.shape[1]:frame_cam.shape[1],frame.shape[0]:frame_cam.shape[0]]\n",
    "\n",
    "        # Redimensiona a imagem da câmera para que tenha o mesmo tamanho do vídeo\n",
    "        frame_cam = cv2.resize(frame_cam, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "        # Concatena as imagens horizontalmente\n",
    "        combined_frame = cv2.hconcat([frame, frame_cam])\n",
    "\n",
    "        # Exibe a imagem combinada em uma janela\n",
    "        cv2.imshow('Combined Video and Camera Feed', combined_frame)\n",
    "\n",
    "        # Aguarda 1ms por uma tecla para ser pressionada\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Verifica se o vídeo terminou\n",
    "        if not cap.isOpened():\n",
    "            break\n",
    "\n",
    "    # Libera os recursos\n",
    "    cap.release()\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "# Define as configurações da janela\n",
    "janela = tk.Tk()\n",
    "janela.geometry('300x150')\n",
    "janela.title('Janela de Início')\n",
    "\n",
    "# Define o título e a fonte do botão \"Começar\"\n",
    "titulo = tk.Label(janela, text='Bem-vindo(a)!', font=('Arial', 16))\n",
    "titulo.pack(pady=10)\n",
    "botao = tk.Button(janela, text='Começar', font=('Arial', 14), command=iniciar_video, bg='#000')\n",
    "botao.pack(fill='both', expand=True, padx=20, pady=10)\n",
    "\n",
    "# Define a cor de fundo da janela\n",
    "janela.configure(bg='#bbb')\n",
    "\n",
    "# Inicia a janela\n",
    "janela.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "import time\n",
    "\n",
    "def iniciar_video():\n",
    "    janela.destroy()\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Inicializa a variável \"frame\"\n",
    "    frame = None\n",
    "    \n",
    "    # Define o momento de início do jogo\n",
    "    inicio_jogo = None\n",
    "    \n",
    "    # Define o tempo máximo para o jogo (em segundos)\n",
    "    tempo_maximo_jogo = 30\n",
    "    \n",
    "    while True:\n",
    "        # Lê frame da câmera\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Verifica se a câmera foi lida corretamente\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Exibe a imagem em uma janela\n",
    "        cv2.imshow('Camera Feed', frame)\n",
    "        \n",
    "        # Exibe o texto \"Balance a mão para começar o jogo\" por 5 segundos\n",
    "        if inicio_jogo is None:\n",
    "            cv2.putText(frame, \"Balance a mão para começar o jogo\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.imshow('Camera Feed', frame)\n",
    "            cv2.waitKey(5000)\n",
    "            inicio_jogo = time.time()\n",
    "\n",
    "        # Verifica se o tempo máximo do jogo foi atingido\n",
    "        tempo_decorrido = time.time() - inicio_jogo\n",
    "        if tempo_decorrido >= tempo_maximo_jogo:\n",
    "            break\n",
    "\n",
    "        # Verifica se a tecla \"q\" foi pressionada\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Libera os recursos\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Cria janela com o botão \"Começar\"\n",
    "janela = tk.Tk()\n",
    "janela.geometry('200x100')\n",
    "botao = tk.Button(janela, text='Começar', command=iniciar_video)\n",
    "botao.pack(fill='both', expand=True)\n",
    "janela.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n",
      "Balançou a mão!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define ROI para detectar a mão\n",
    "x, y, w, h = 100, 100, 200, 200\n",
    "\n",
    "# Inicializa o primeiro frame\n",
    "ret, frame_ant = cap.read()\n",
    "gray_ant = cv2.cvtColor(frame_ant, cv2.COLOR_BGR2GRAY)\n",
    "gray_ant = cv2.GaussianBlur(gray_ant, (21, 21), 0)\n",
    "\n",
    "while True:\n",
    "    # Lê frame atual\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "    # Calcula diferença entre frames\n",
    "    diff = cv2.absdiff(gray_ant, gray)\n",
    "    _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    # Desenha ROI na imagem\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Verifica se a mão foi balançada\n",
    "    roi = thresh[y:y+h, x:x+w]\n",
    "    if cv2.countNonZero(roi) > 500:\n",
    "        print(\"Balançou a mão!\")\n",
    "\n",
    "    # Atualiza o frame anterior\n",
    "    gray_ant = gray\n",
    "\n",
    "    # Exibe a imagem em uma janela\n",
    "    cv2.imshow(\"Camera\", frame)\n",
    "\n",
    "    # Aguarda 1ms por uma tecla para ser pressionada\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Libera os recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
